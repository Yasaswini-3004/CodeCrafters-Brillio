{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ki0azDgwRE3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Install the required packages**"
      ],
      "metadata": {
        "id": "mBpIH5Ha6QEu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VqqTRC36F90",
        "outputId": "7973b558-0493-4abb-8c56-9e9b503b2458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/232.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-docx\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/239.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n",
            "Installing collected packages: python-docx, PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1 python-docx-1.1.0\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.23.7-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n",
            "Collecting PyMuPDFb==1.23.7 (from pymupdf)\n",
            "  Downloading PyMuPDFb-1.23.7-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, pymupdf\n",
            "Successfully installed PyMuPDFb-1.23.7 pymupdf-1.23.7\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=6a17bf1b9b7e53633a6df65b0c2e9330bf75427530418024bc643cd16190c5db\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (41.0.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Installing collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20221105\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.10/dist-packages (1.23.7)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.7 in /usr/local/lib/python3.10/dist-packages (from pymupdf) (1.23.7)\n",
            "Collecting spacy==2.3.5\n",
            "  Downloading spacy-2.3.5.tar.gz (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (3.0.9)\n",
            "Collecting thinc<7.5.0,>=7.4.1 (from spacy==2.3.5)\n",
            "  Using cached thinc-7.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (0.7.11)\n",
            "Collecting wasabi<1.1.0,>=0.4.0 (from spacy==2.3.5)\n",
            "  Using cached wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Collecting srsly<1.1.0,>=1.0.2 (from spacy==2.3.5)\n",
            "  Using cached srsly-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (369 kB)\n",
            "Collecting catalogue<1.1.0,>=0.0.7 (from spacy==2.3.5)\n",
            "  Using cached catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (4.66.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (67.7.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (1.23.5)\n",
            "Collecting plac<1.2.0,>=0.9.6 (from spacy==2.3.5)\n",
            "  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (2023.11.17)\n",
            "Building wheels for collected packages: spacy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for spacy \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for spacy (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for spacy\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build spacy\n",
            "\u001b[31mERROR: Could not build wheels for spacy, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spacy<2.4.0,>=2.3.0 (from en-core-web-sm==2.3.1)\n",
            "  Downloading spacy-2.3.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.0.9)\n",
            "Collecting thinc<7.5.0,>=7.4.1 (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1)\n",
            "  Using cached thinc-7.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (0.7.11)\n",
            "Collecting wasabi<1.1.0,>=0.4.0 (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1)\n",
            "  Using cached wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Collecting srsly<1.1.0,>=1.0.2 (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1)\n",
            "  Using cached srsly-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (369 kB)\n",
            "Collecting catalogue<1.1.0,>=0.0.7 (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1)\n",
            "  Using cached catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (4.66.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (67.7.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.23.5)\n",
            "Collecting plac<1.2.0,>=0.9.6 (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1)\n",
            "  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2023.11.17)\n",
            "Building wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047086 sha256=5760d483589af0147bb6a69343efe652bb5c789e05d96a9f943407304694798b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/1f/0e/16fae4b01d2d87454e0f484e58c48793efcf237f0894c1c4bd\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: wasabi, plac, srsly, catalogue, thinc, spacy, en-core-web-sm\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.2\n",
            "    Uninstalling wasabi-1.1.2:\n",
            "      Successfully uninstalled wasabi-1.1.2\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.8\n",
            "    Uninstalling srsly-2.4.8:\n",
            "      Successfully uninstalled srsly-2.4.8\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.10\n",
            "    Uninstalling catalogue-2.0.10:\n",
            "      Successfully uninstalled catalogue-2.0.10\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.12\n",
            "    Uninstalling thinc-8.1.12:\n",
            "      Successfully uninstalled thinc-8.1.12\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 3.6.0\n",
            "    Uninstalling en-core-web-sm-3.6.0:\n",
            "      Successfully uninstalled en-core-web-sm-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "confection 0.1.4 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed catalogue-1.0.2 en-core-web-sm-2.3.1 plac-1.1.3 spacy-2.3.9 srsly-1.0.7 thinc-7.4.6 wasabi-0.10.1\n",
            "Collecting pyresparser\n",
            "  Downloading pyresparser-1.0.6-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (23.1.0)\n",
            "Requirement already satisfied: blis>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (0.7.11)\n",
            "Requirement already satisfied: certifi>=2019.6.16 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2023.11.17)\n",
            "Requirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (5.2.0)\n",
            "Requirement already satisfied: cymem>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.0.8)\n",
            "Requirement already satisfied: docx2txt>=0.7 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (0.8)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.6)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (4.19.2)\n",
            "Requirement already satisfied: nltk>=3.4.3 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.5.3)\n",
            "Requirement already satisfied: pdfminer.six>=20181108 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (20221105)\n",
            "Requirement already satisfied: preshed>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.0.9)\n",
            "Collecting pycryptodome>=3.8.2 (from pyresparser)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyrsistent>=0.15.2 (from pyresparser)\n",
            "  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2019.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2023.3.post1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.31.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.16.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.4.0)\n",
            "Requirement already satisfied: spacy>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.3.9)\n",
            "Requirement already satisfied: srsly>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.0.7)\n",
            "Requirement already satisfied: thinc>=7.0.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (7.4.6)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (4.66.1)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.0.7)\n",
            "Requirement already satisfied: wasabi>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (0.10.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (0.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six>=20181108->pyresparser) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six>=20181108->pyresparser) (41.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from preshed>=2.0.1->pyresparser) (1.0.10)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (67.7.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (1.1.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (2.21)\n",
            "Installing collected packages: pyrsistent, pycryptodome, pyresparser\n",
            "Successfully installed pycryptodome-3.19.0 pyresparser-1.0.6 pyrsistent-0.20.0\n",
            "Collecting tabula-py\n",
            "  Downloading tabula_py-2.9.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.23.5)\n",
            "Requirement already satisfied: distro in /usr/lib/python3/dist-packages (from tabula-py) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.25.3->tabula-py) (1.16.0)\n",
            "Installing collected packages: tabula-py\n",
            "Successfully installed tabula-py-2.9.0\n",
            "Collecting resume-parser\n",
            "  Downloading resume_parser-0.8.4-py3-none-any.whl (9.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: docx2txt>=0.8 in /usr/local/lib/python3.10/dist-packages (from resume-parser) (0.8)\n",
            "Requirement already satisfied: nltk>=3.5 in /usr/local/lib/python3.10/dist-packages (from resume-parser) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from resume-parser) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from resume-parser) (1.5.3)\n",
            "Requirement already satisfied: pdfminer.six>=20200517 in /usr/local/lib/python3.10/dist-packages (from resume-parser) (20221105)\n",
            "Collecting pdfplumber>=0.5.23 (from resume-parser)\n",
            "  Downloading pdfplumber-0.10.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.0/49.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting phonenumbers>=8.12.7 (from resume-parser)\n",
            "  Downloading phonenumbers-8.13.26-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from resume-parser) (2.3.9)\n",
            "Collecting stemming>=1.0.1 (from resume-parser)\n",
            "  Downloading stemming-1.0.1.zip (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tika>=1.24 (from resume-parser)\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.5->resume-parser) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.5->resume-parser) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.5->resume-parser) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.5->resume-parser) (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->resume-parser) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->resume-parser) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six>=20200517->resume-parser) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six>=20200517->resume-parser) (41.0.7)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber>=0.5.23->resume-parser) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.5.23->resume-parser)\n",
            "  Downloading pypdfium2-4.24.0-py3-none-manylinux_2_17_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.2->resume-parser) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.2->resume-parser) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.2->resume-parser) (3.0.9)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.2->resume-parser) (7.4.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.2->resume-parser) (0.7.11)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.2->resume-parser) (0.10.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.2->resume-parser) (1.0.7)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.2->resume-parser) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.2->resume-parser) (67.7.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.2->resume-parser) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.2->resume-parser) (2.31.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six>=20200517->resume-parser) (1.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.0->resume-parser) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.2->resume-parser) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.2->resume-parser) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.2->resume-parser) (2023.11.17)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20200517->resume-parser) (2.21)\n",
            "Building wheels for collected packages: stemming, tika\n",
            "  Building wheel for stemming (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stemming: filename=stemming-1.0.1-py3-none-any.whl size=11123 sha256=665eb23adf5d56ef04d9c8748c5c73c29617a2a6b19b9ce13690272f6b30b9c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/f9/3f/8fe1ec182ce66145d7ded39bad9a690960469dc350fbec0181\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32622 sha256=77b2052cec7784806f20af0da3a64602fc64e23e6e5e31920f2b4aec1242fa78\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
            "Successfully built stemming tika\n",
            "Installing collected packages: stemming, phonenumbers, pypdfium2, tika, pdfplumber, resume-parser\n",
            "Successfully installed pdfplumber-0.10.3 phonenumbers-8.13.26 pypdfium2-4.24.0 resume-parser-0.8.4 stemming-1.0.1 tika-2.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2 python-docx\n",
        "!pip install python-docx pymupdf\n",
        "!pip install docx2txt\n",
        "!pip install pdfminer.six\n",
        "!pip install pymupdf\n",
        "!pip install spacy==2.3.5\n",
        "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
        "!pip install pyresparser\n",
        "!pip install tabula-py\n",
        "!pip install resume-parser"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Natural Language Toolkit**"
      ],
      "metadata": {
        "id": "rqcI1NMVQXdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('brown')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEac9Oxe6gzA",
        "outputId": "a0f99fd2-ea22-41a1-f18b-7f6e58e78142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import ResumeParser**"
      ],
      "metadata": {
        "id": "2uEiQdQYQdn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyresparser import ResumeParser\n",
        "import warnings"
      ],
      "metadata": {
        "id": "woZJD-ua6gvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "id": "IeD5E4UD6p-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ****Extracting data from resume****"
      ],
      "metadata": {
        "id": "0rPkcr4z6877"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 15 resumes for testing"
      ],
      "metadata": {
        "id": "gS-3ofgNd0LU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from resume_parser import resumeparse\n",
        "\n",
        "def extract_name_from_filename(filename):\n",
        "    # This is a simplified example. You might need a more sophisticated logic based on your filename format.\n",
        "    # For example, if filenames are in the format \"FirstName_LastName_Resume.docx\"\n",
        "    # you might want to split on underscores and take the first and last parts as the first and last name.\n",
        "    # Adjust this function based on your actual filename format.\n",
        "    return os.path.splitext(filename)[0]  # Just using the filename without extension as an example\n",
        "\n",
        "def save_to_csv(output_file, data, filename):\n",
        "    fieldnames = [\"Filename\", \"FullName\", \"Name\", \"Email\", \"Mobile Number\", \"Skills\", \"College Name\", \"Degree\", \"Designation\", \"Company Names\", \"Total Experience\"]\n",
        "\n",
        "    # Check if the file already exists\n",
        "    file_exists = os.path.isfile(output_file)\n",
        "\n",
        "    with open(output_file, 'a', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        # If the file doesn't exist, write the header\n",
        "        if not file_exists:\n",
        "            writer.writeheader()\n",
        "\n",
        "        # Extract name from the filename\n",
        "        full_name = extract_name_from_filename(filename)\n",
        "\n",
        "        # Write data\n",
        "        writer.writerow({\n",
        "            \"Filename\": filename,\n",
        "            \"FullName\": full_name,\n",
        "            \"Name\": data[\"name\"],\n",
        "            \"Email\": data[\"email\"],\n",
        "            \"Mobile Number\": data[\"phone\"],\n",
        "            \"Skills\": \", \".join(data[\"skills\"]),\n",
        "            \"College Name\": data[\"university\"],\n",
        "            \"Degree\": data[\"degree\"],\n",
        "            \"Designation\": data[\"designition\"],\n",
        "            \"Company Names\": \", \".join(data[\"Companies worked at\"]),\n",
        "            \"Total Experience\": data[\"total_exp\"]\n",
        "        })\n",
        "\n",
        "def process_resume_folder(folder_path, output_csv_file, num_resumes=15):\n",
        "    count = 0\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if count >= num_resumes:\n",
        "            break\n",
        "\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        if os.path.isfile(file_path):\n",
        "            try:\n",
        "                resume_info = resumeparse.read_file(file_path)\n",
        "                save_to_csv(output_csv_file, resume_info, file_name)\n",
        "                count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_name}: {e}\")\n",
        "\n",
        "# Example usage for a folder containing resume files\n",
        "resume_folder_path = \"/content/drive/MyDrive/Resumes/\"\n",
        "output_csv_file = \"resume_data.csv\"\n",
        "\n",
        "# Process the first 15 resumes in the folder and append information to the existing CSV file\n",
        "process_resume_folder(resume_folder_path, output_csv_file, num_resumes=15)\n",
        "\n",
        "print(f\"Data appended to {output_csv_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdzuM1Izdz2g",
        "outputId": "6b21d26a-ef52-4ec2-8b26-c1ad4a576e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-12-04 05:50:05,841 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/2.6.0/tika-server-standard-2.6.0.jar to /tmp/tika-server.jar.\n",
            "INFO:tika.tika:Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/2.6.0/tika-server-standard-2.6.0.jar to /tmp/tika-server.jar.\n",
            "2023-12-04 05:50:06,072 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/2.6.0/tika-server-standard-2.6.0.jar.md5 to /tmp/tika-server.jar.md5.\n",
            "INFO:tika.tika:Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/2.6.0/tika-server-standard-2.6.0.jar.md5 to /tmp/tika-server.jar.md5.\n",
            "2023-12-04 05:50:06,304 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n",
            "WARNING:tika.tika:Failed to see startup log message; retrying...\n",
            "ERROR:root:invalid literal for int() with base 10: 'date'\n",
            "ERROR:root:'NoneType' object has no attribute 'group'\n",
            "ERROR:root:'NoneType' object has no attribute 'group'\n",
            "ERROR:root:invalid literal for int() with base 10: 'Mar 2015'\n",
            "ERROR:root:invalid literal for int() with base 10: 'JULY2014'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data appended to resume_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entire dataset"
      ],
      "metadata": {
        "id": "IkMsejlMdx2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from resume_parser import resumeparse\n",
        "\n",
        "def extract_name_from_filename(filename):\n",
        "    return os.path.splitext(filename)[0]\n",
        "\n",
        "def save_to_csv(output_file, data, filename):\n",
        "    fieldnames = [\"Filename\", \"FullName\", \"Name\", \"Email\", \"Mobile Number\", \"Skills\", \"College Name\", \"Degree\", \"Designation\", \"Company Names\", \"Total Experience\"]\n",
        "\n",
        "    # Check if the file already exists\n",
        "    file_exists = os.path.isfile(output_file)\n",
        "\n",
        "    with open(output_file, 'a', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        # If the file doesn't exist, write the header\n",
        "        if not file_exists:\n",
        "            writer.writeheader()\n",
        "\n",
        "        # Extract name from the filename\n",
        "        full_name = extract_name_from_filename(filename)\n",
        "\n",
        "        # Write data\n",
        "        writer.writerow({\n",
        "            \"Filename\": filename,\n",
        "            \"FullName\": full_name,\n",
        "            \"Name\": data[\"name\"],\n",
        "            \"Email\": data[\"email\"],\n",
        "            \"Mobile Number\": data[\"phone\"],\n",
        "            \"Skills\": \", \".join(data[\"skills\"]),\n",
        "            \"College Name\": data[\"university\"],\n",
        "            \"Degree\": data[\"degree\"],\n",
        "            \"Designation\": data[\"designition\"],\n",
        "            \"Company Names\": \", \".join(data[\"Companies worked at\"]),\n",
        "            \"Total Experience\": data[\"total_exp\"]\n",
        "        })\n",
        "\n",
        "def process_resume_folder(folder_path, output_csv_file):\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        if os.path.isfile(file_path):\n",
        "            try:\n",
        "                resume_info = resumeparse.read_file(file_path)\n",
        "                save_to_csv(output_csv_file, resume_info, file_name)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_name}: {e}\")\n",
        "\n",
        "# Example usage for a folder containing resume files\n",
        "resume_folder_path = \"/content/drive/MyDrive/Resumes/\"\n",
        "output_csv_file = \"all_resume_data.csv\"\n",
        "\n",
        "# Process all resumes in the folder and append information to the existing CSV file\n",
        "process_resume_folder(resume_folder_path, output_csv_file)\n",
        "\n",
        "print(f\"Data appended to {output_csv_file}\")"
      ],
      "metadata": {
        "id": "t1jqQ1gR6p61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_J6p6O06p4W",
        "outputId": "532501c4-65b0-48eb-c134-c27ddd60e462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/221.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/221.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using OpenAI to generate tags**"
      ],
      "metadata": {
        "id": "Mk29PKu-QtBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "# Input your OpenAI API key here\n",
        "openai_api_key = \"YOUR API_KEY"\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv('/content/resume_data.csv')\n",
        "\n",
        "# Initialize the OpenAI client with your API key\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "# Iterate over each row in the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    # Extract the content from the 'Skills' column\n",
        "    user_content = row['Skills']\n",
        "\n",
        "    # Create a chat completion\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a recruitment assistant\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Generate skills tags from this content I provide, please remove extra spaces and unnecessary tags, only useful tags should be: {user_content}\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Access the generated content\n",
        "    generated_content = completion.choices[0].message.content\n",
        "\n",
        "    # Set the generated content in the 'generated_tags' column for the current row\n",
        "    df.loc[index, 'generated_tags'] = generated_content\n",
        "\n",
        "# Save the updated DataFrame back to the CSV file\n",
        "df.to_csv('/content/resume_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "giXmlW7OgPse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Converting the output csv file to json file**"
      ],
      "metadata": {
        "id": "1Us9shCfQ34b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the final output CSV file into a DataFrame\n",
        "df = pd.read_csv('/content/resume_data.csv')\n",
        "\n",
        "# Convert the DataFrame to JSON format with indentation\n",
        "json_output = df.to_json(orient='records', indent=2)  # Adjust the indentation level as needed\n",
        "\n",
        "# Save the JSON output to a file\n",
        "output_json_file = '/content/resume_data.json'\n",
        "with open(output_json_file, 'w') as json_file:\n",
        "    json_file.write(json_output)\n",
        "\n",
        "print(f\"JSON data saved to {output_json_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVYzdmOThReN",
        "outputId": "b2baf4c1-f2a4-4438-ba4b-622479b4ec2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON data saved to /content/resume_data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LEXQAa_OifFu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
